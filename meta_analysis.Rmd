---
title: "Meta Analysis"
author: "Quyen Duong"
date: "Last edited `r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
---

```{r setup, include = FALSE}
# Set the default mode for all the chunks
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center", 
                      fig.height = 6, fig.width = 8)
```

```{r load-packages, include=FALSE}
library(quantmod)              # download stock price
library(tidyverse)
library(dplyr)
library(ggplot2)
library(tseries)               # for ts object, ADF test
library(forecast)              # to predict price 
library(prophet)
library(astsa)                 # for ARIMA model, check residual
library(PerformanceAnalytics)  # compute returns
library(rugarch)               # for GARCH
library(xts)
```

# Introduction

## Motivation
The goal of the study is to compare three different machine learning methods to predict Meta stock price:

* ARIMA: Auto-regressive integrated moving average
* GARCH: Generalized auto-regressive conditional heteroskedasticity
* Prophet: a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data ^[https://facebook.github.io/prophet/]. 

## Methodology
Add text here 

```{r load-data}
# Downloading Meta ("FB") via Yahoo Finance API
Meta <- NULL
tickers_index <- c("FB")

for (Ticker in tickers_index) {
  Meta <- cbind(
    Meta,
    getSymbols.yahoo(
      Ticker,
      from = "2015-01-01",
      to = "2021-11-30",          
      periodicity = "daily",
      auto.assign = FALSE
    )[, 6]                        # Only adjusted close
  )
}

# Change Meta to dataframe
d_meta <- broom::tidy(Meta)

# Select relevant columns & change column names
d_meta <- d_meta %>% select(index, value) %>% 
  rename(date_meta = index, price_meta = value)

# Glimpse on the data
glimpse(d_meta)
```

# Descriptive analysis

## Stock price

Let's first have a look at the time series:

```{r plot-timeseries}
# Plot the time series
plot(Meta)

# Boxplot 
ggplot(data = Meta, aes(y = Meta)) +
  geom_boxplot() +
  labs(title="Boxplot of Meta", y = "Price")
```

Meta price plot displays multiplicative trend and multiplicative seasonality. Besides, the boxplot shows some observations at the larger value. The important task at this stage is assess the time series' stationary. Obviously, according to the plot above, it is not stationary. Yet, we conduct the Augmented Dickey-Fuller (ADF), a so-called test to check whether a time series is (non-)stationary. The hypotheses are formed as follows:

* $H_{0}: \rho = 1$: Time series has a unit root, hence, non-stationary, shows a trend over time 
* $H_{1}: -1 < \rho < 1$: Time series is stationary

```{r ADF-test-price, include = TRUE}
# Conduct ADF test for price
adf.test(Meta)
```

p-value = 0.53 > $\alpha$ of 0.05: fail to reject $H_{0}$, this time series is not stationary.

```{r ADF-test-log-price}
# Conduct ADF test for logged price
adf.test(log(Meta))
```

p-value = 0.22 > $\alpha$ of 0.05: fail to reject $H_{0}$, this log-transformed time series is not stationary.


### Decompose the time series

```{r decompose-ts}
# Create timeseries object with frequency 260 days/year (according to Bieri(2021))
ts_meta <- ts(d_meta$price_meta, start = c(2015, 1), frequency = 260)

# Seasonal Decomposition of Time Series by Loess
stl_meta <- stl(ts_meta, s.window = "periodic")
plot(stl_meta)
```

## Continous returns

It's even more essential to check the histogram of Meta returns. In this case, we put the histogram and boxplot together in one graph to provide a comprehensive view over the returns:

```{r histogram-return}
# Calculating continuous returns 
returns_meta <- na.omit(diff(log(Meta)))
colnames(returns_meta)<-"returns_meta"

# Histogram
histogram_meta_return <- ggplot(returns_meta, mapping = aes(x = returns_meta)) +
  geom_histogram(color="black", fill = "grey", bins = 50) +
  #geom_density(alpha=.2, color ="blue") +
  scale_x_continuous() +
  labs(title = "Histogram and boxplot of Meta returns") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# Boxplot
boxplot_meta_return <- ggplot(returns_meta, mapping = aes(x = "", y = returns_meta)) +
  geom_boxplot(color = "black", fill = "grey") +
  scale_y_continuous() +
  coord_flip() +
  xlab("") +
  theme_minimal()

# Display two plots together
egg::ggarrange(histogram_meta_return, boxplot_meta_return, heights = 2:1)
```

The histogram of Meta returns looks quite bell-shaped with many tails on both sides but let's check the basic statistics for skewness and kurtosis. 

```{r Skewness-Kurtosis-return}
psych::describe(returns_meta)
```

* Skew = -0.7: Moderate skewed distribution with long. Remarkably, there are two data points on the far left presenting the two negative returns.
* Kurtosis = 13: Leptokurtic distribution with long tails and concentrated toward the mean. Compared to a normal distribution, its tails are longer and fatter, and often its central peak is higher and sharper. ^[https://www.investopedia.com/terms/k/kurtosis.asp]

```{r plot-return}
# Plot the returns
plot(returns_meta)


```

As expected from Kurtosis, the plot of returns exhibits constant trend around the mean of 0. Nevertheless, the return variability changes and is not constant over time (i.e. high volatility). We test ADF once more time with the returns:

```{r ADF-test-returns, include = TRUE}
# Conduct ADF test for the returns
adf.test(returns_meta)
```

p-value = 0.01 < $\alpha$: reject $H_{0}$: The continuous returns are stationary. 

# Fitting models

## Train and test data

The time series are divided into train (day 1 2015 - day 150 2021) and test (day 151 2021 - day 180 2021) sets.

```{r train-test-split}
train <- window(ts_meta, start = c(2015, 1), end=c(2021, 150))
test <- window(ts_meta, start=c(2021, 151), end = c(2021, 180))
```

## ARIMA

To fit an ARIMA model, we must perform preliminary checks:

- Is the model stationary?
- Do the properties of (P)ACF match?
- Which orders of p, d, q?

### Manually choosing model

```{r acf-pacf-log-meta}
# ACF & PACF of logged meta
tsdisplay(log(Meta), points = FALSE)
```

Observations: 

- ACF decays in a linear fashion and outside of the confidence band.
- PACF is almost at 1 and clear cuts off at lag 1. 

```{r ARIMA-manual}
# Identifying p, q of the ARIMA(p,1,q)-model by testing different specifications
max.order <- 6 # We only allow a maximum of 6 AR- and/or MA-terms 
d <- 1         # we difference at lag 1 then the time series became stationary

# Defining the matrix in for values of the AICs for different model specifications are stored
arima_aic <- matrix(NA, ncol=max.order+1, nrow=max.order+1)
row.names(arima_aic) <- c(0:max.order) # Order of AR(p) in rows
colnames(arima_aic) <- c(0:max.order) # Order of MA(q) in columns

# Calculating and storing the AICs for different model specifications
for(i in 0:max.order){
  for(j in 0:max.order){
    arima_aic[i+1,j+1] <- Arima(y=log(train), order=c(i,d,j), include.constant = TRUE)$aic
  }
}

# Finding the model specification which minimizes the AIC
index <- which(arima_aic == min(arima_aic), arr.ind = TRUE)
ar <- as.numeric(rownames(arima_aic)[index[1]])
ma <- as.numeric(colnames(arima_aic)[index[2]])

# Estimating the optimal ARIMA-model and testing for significance of the coefficients
fit_arima <- Arima(y=log(train), order=c(ar,1,ma), include.constant = TRUE)
```

Using matrix to calculate and choose the min of AIC, the result is ARIMA(4,1,4) with drift.

### Auto-Arima

```{r auto-arima}
# Fit an auto-arima
fit_auto_ari <- auto.arima(y = log(train), ic = "aic", trace = TRUE)
fit_auto_ari

# Which one ???
auto.arima(y = Meta, ic = "aic")
```

Using auto.arima, we got ARIMA(0,1,1) with drift. 

### Residual analysis

The goal of this part is to ensure that the residuals are white Gaussian noise. After getting ARIMA(0,1,1) from auto.arima and ARIMA(4,1,4) from the matrix, we evaluate the residuals of these two models. `Sarima()` function is a very compacted to get all of needed graphs at once, hence we use it here to analyse the residuals:

```{r residual-check-auto-arima, results='hide',fig.keep='all'}
# Use sarima from package astsa because many plots shown
# Check residuals ARIMA(0,1,1)
sarima(log(train), 0,1,1)

## Check residuals ARIMA(4,1,4)
sarima(log(train), 4,1,4)
```

Observations:

- Standardized residuals: hard to say if there is an obvious pattern.
- Sample ACF of residuals: 95% of the ACF values should be between the confidence band. ARIMA(4,1,4) has more ACF stay in the confidence range. 
- Normal Q-Q plot: if the residuals are normal, the points will be in the blue line. However, there are often extreme value on the ends as in the graph. If there are no huge departures from the line, the normal assumption is reasonable.
- Q-statistic p-values: if most points are above the blue lines, we can assume white noise. If this is not the case, there might be some correlation left in the residuals, we might consider to fit another model or add a parameter. Here, the bottom plot of ARIMA(0,1,1) displays two points above the line but the rest are touching or under the line. In contrast, the Lijung-Box for ARIMA(4,1,4) shows all the points above the line.
- AIC and AICc of ARIMA(4,1,4) are smaller than ARIMA(0,1,1). In contrast, BIC of ARIMA(0,1,1) is smaller than that of ARIMA(4,1,4). (i.e. -4.98 < -4.97)

### Validation by fit inspection

```{r actual-resid-plot}
plot(log(train))
lines(log(train) - resid(fit_arima), col = "blue")
legend(x = "bottomright",          
       legend = c("Actual price", "Fitted model price"),
       lty = c(1, 1),           
       col = c("black", "blue")) 
title("Fitted model price and actual price")
```

The plot indicates that the model fits quite well. 

### Forecasting

Conclusion: Our chosen model is ARIMA(4,1,4). Even though ARIMA(0,1,1) has lower BIC, BIC typically leads to a more conservative model specification as the penalty for the number of coefficients to be estimated is higher than for AIC ^[Bieri, D. (2021)]. In contrast, ARIMA(4,1,4) leads to lower AIC and AICc. Also, we selected this model based on our residual diagnostics as the residual of ARIMA(4,1,4)'s noise is white. 

```{r forecast-arima}
# Creating 2 windows 
## From the beginning to day 150, 2021
window1_meta <- window(ts_meta, end = c(2021, 150))
## From the beginning to day 180, 2021
window2_meta <- window(ts_meta, end = c(2021, 180))

# Forecasting 30 days using astsa package 
sarima.for(log(window1_meta), n.ahead = 30, 4, 1, 4)
lines(log(window2_meta))

# Forecasting 60 days using forecast
pred_arima <- forecast(fit_arima, level = 0.95, h = 60)
autoplot(pred_arima, ylab="Meta")
```

### Measuring model accuracy

```{r accuracy-comparison}
# Check RMSE and MAPE of the fit_auto_ari ARIMA(0,1,1)
accuracy(fit_auto_ari)

# Check RMSE and MAPE of the fit_arima ARIMA(4,1,4)
accuracy(fit_arima)
```

Observations:

- MAPE and RMSE of ARIMA(4,1,4) are slightly smaller than MAPE of ARIMA(0,1,1)
- Overall, the two models have around 26% of error on average prediction compared to the true value. 

```{r accuracy-train-test-set}
# Fit the chosen model ARIMA(4,1,4) for the test data
fit_arima_test <- Arima(log(test), model = fit_arima)

# Check RMSE & MAPE for the test data
accuracy(fit_arima_test)

# Check RMSE & MAPE for the train data
accuracy(fit_arima)

# Check RMSE & MAPE for the whole data
fit_arima_all <-  Arima(log(Meta), order=c(4,1,4), include.constant = TRUE)
accuracy(fit_arima_all)
```

Observations:

- RMSE of test data = 0.019, which is slightly lower than the train data (0.02)
- In contrasts, MAPE of test data is slightly lower than the train data (0.255 < 0.261)
- When we fit similar model for the whole time series, RMSE = 0.02 & MAPE =  0.26

## GARCH

GARCH model is used to predict volatility of the future returns. GARCH model is used to predict volatility of the future returns. To be more specific, the GARCH approach models the variance using the prediction errors $e_{t}$ (also called shocks or unexpected returns). The parameter $\alpha$ determines the reactivity to $e_{t}^2$, while $\beta$ is the weight on the previous variance prediction. 

```{r volatility}
# Discrete return with log transform
meta_discrete_returns <- CalculateReturns(Meta)

## Remove the 1st row because of NA value
meta_discrete_returns <- meta_discrete_returns$FB.Adjusted[!is.na(meta_discrete_returns$FB.Adjusted)]

# Return daily volatility
sd(na.omit(meta_discrete_returns))

# Annualized volatility
sqrt(252) * sd(meta_discrete_returns)
```

For the daily Meta returns, this gives us a daily volatility of around 2% and 32% of annualized volatility.  

```{r rolling-volatility-plot}
chart.RollingPerformance(R = meta_discrete_returns,
                         width = 22,                # one month = 22 trading days
                         FUN = "sd.annualized",
                         scale = 252, 
                         main = "Rolling one month volatility")

plot(meta_discrete_returns)
```

```{r absolute-prediction-errors}
# Compute the mean daily return
m <- mean(meta_discrete_returns)

# Define the series of prediction errors
e <- meta_discrete_returns - m

# Plot the absolute value of the prediction errors
par(mfrow = c(2,1))
plot(abs(e))

# Plot the acf of the absolute prediction errors
acf(abs(na.omit(e)))
```

The top plot shows the waves in the absolute prediction errors. They indicate the presence of high and low volatility clusters. In the bottom plot, we can see the positive autocorrelations in the absolute prediction errors. Many of them are above 0.1. 

Here, we use the `rugarch` package to fit the GARCH models for the data.

### GARCH volatility

We start first with the simple standard GARCH(1,1):

```{r sGARCH}
par(mfrow = c(1,1))

# Specify a standard GARCH model with constant mean
garchspec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),
                        variance.model = list(model = "sGARCH"), 
                        distribution.model = "sstd") #student t 

# Estimate the model
garchfit <- ugarchfit(data = meta_discrete_returns, spec = garchspec)

# Inspect the coefficients
coef(garchfit)

# Use the method sigma to retrieve the estimated volatilities 
garchvol <- sigma(garchfit)

# Plot the volatility for 2020
plot(garchvol["2020"])
```

For Meta, skew $\approx$ 1 indicating a moderate skewed distribution. Degree of freedom shape is around 4, indicating fat tails. 

```{r garch-prediction}
# Compute unconditional volatility
sqrt(uncvariance(garchfit))

# Print last 10 ones in garchvol
tail(garchvol, 10)

# Forecast volatility 5 days ahead and add 
garchforecast <- ugarchforecast(fitORspec = garchfit, 
                                n.head = 5)

# Extract the predicted volatilities and print them
print(sigma(garchforecast))
```

A portfolio that invests a percentage $w$ in a risky asset (with volatility $\sigma$) and keeps $1 - w$ on a risk-free bank deposit account has volatility equal to:

$$\sigma_{p} = w\sigma_{t}$$
How to set $w$? One approach is volatility targeting: $w$ is such that the predicted annualized portfolio volatility equals a target level, say 5%. Then: 

$$w^* = \frac{0.05}{\sigma_{t}}$$
GARCH volatility predictions are of direct practical use in portfolio allocation. According to the two-fund separation theorem of James Tobin, we should invest a proportion $w$ of our wealth in a risky portfolio and the remainder in a risk free asset, like a US Treasury bill.

When we target a portfolio with 5% annualized volatility, and the annualized volatility of the risky asset is $\sigma_{t}$, then we should invest $\frac{0.05}{\sigma_{t}}$ in the risky asset.

```{r}
# Compute the annualized volatility
annualvol <- sqrt(252) * sigma(garchfit)

# Compute the 5% vol target weights  
vt_weights <- 0.05 / annualvol

# Compare the annualized volatility to the portfolio weights in a plot
plot(merge(annualvol, vt_weights), multi.panel = TRUE)
```

### GJR GARCH

Negative news about returns affect the variance more than positive news (leverage effect). The GJR GARCH model allows for asymmetric response of variance to positive and negative news. The news impact curve is a helpful tool to visualize the response of the variance to the surprise in returns.

```{r gjr-garch}
# Specify a GJR GARCH 
gjr_garchspec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),
                            variance.model = list(model = "gjrGARCH"), 
                            distribution.model = "sstd") #student t 

# Estimate the model
gjr_garchfit <- ugarchfit(data = meta_discrete_returns, spec = garchspec)

# Inspect the coefficients
coef(gjr_garchfit)[2:5]

# Use the method sigma to retrieve the estimated volatilities 
gjr_garchvol <- sigma(gjr_garchfit)

# Compare volatility from 2 model sGARCH and gjrGARCH
plotvol <- plot(abs(meta_discrete_returns), col = "grey")
plotvol <- addSeries(gjr_garchvol, col = "red", on=1, lwd=2)
plotvol <- addSeries(garchvol, col = "blue", on=1, lty = "longdash", lwd = 2)
plotvol
```

The red and blue lines look no difference because there have been no financial crisis from 2015 till today. 

### GARCH-in-mean model

A GARCH-in-mean model exploits the relationship between the expected return and the variance of the return.The higher the risk in terms of variance, the higher should be the expected return on investment.

* Quantify the risk-reward trade-off.
* Risk: $\sigma_{t}^2$
* Reward: $\mu_{t}$
* GARCH-in-mean model: 

$$\mu_{t} = \mu + \lambda \sigma_{t}^2$$


```{r GARCH-in-mean-model}
# Specify GJR GARCH-in-mean model
mean_garchspec <- ugarchspec(
  mean.model = list(armaOrder = c(0, 0), archm = TRUE, archpow = 2),
  variance.model = list(model = "gjrGARCH"),
  distribution.model = "sstd")

# Estimate the model
mean_garchfit <- ugarchfit(data = meta_discrete_returns, spec = mean_garchspec)

# Print the first two coefficients
round(coef(mean_garchfit)[1:2], 4)

plot(fitted(mean_garchfit))
```

The estimated model for the reward is:

$$ \hat\mu_{t} = 0.0005 + 1.7259 \hat\sigma_{t}^2 $$
Besides, there are two spikes on 2019 and 2020. 

### AR(1)-GJR GARCH

For the stock prices, the predicted return $\mu_{t}$ is often time-varying. Hence, we use the in-mean GARCH model with AR(1), MA(1), ARMA(1,1).

The GARCH-in-mean uses the financial theory of a risk-reward trade-off to build a conditional mean mode. We use statistical theory to make a mean model that deploys the correlation between today's return and tomorrow's return. Let's look at AR(1) model. AR(1) predicts the next return using the deviation of the return from its long term mean value $\mu$:

$$ \mu_{t} = \mu + \rho(R_{t} - \mu) $$

```{r AR1-GJR-GARCH}
# Specification and estimation of AR(1)-GJR GARCH with sstd distribution
mean_ar1_garchspec <- ugarchspec(
  mean.model = list(armaOrder = c(1, 0)),
  variance.model = list(model = "gjrGARCH"),
  distribution.model = "sstd")

# Estimate the model
mean_ar1_garchfit <- ugarchfit(data = meta_discrete_returns, spec = mean_ar1_garchspec)

# Print the first two coefficients
round(coef(mean_ar1_garchfit)[1:2], 4)
```

Since the AR(1) coefficient in the mean model is negative, indicating overreaction from the market. We therefore find a reversal effect in terms of predicted return. After an above average return, we expect a below average return. Following a below average return, we expect an above average return.

```{r AR1-GJR-GARCH-check-significant}
# Complete and study the statistical significance of the estimated parameters  
round(mean_ar1_garchfit@fit$matcoef, 6)

length(coef(mean_ar1_garchfit))

likelihood(mean_ar1_garchfit)
infocriteria(mean_ar1_garchfit)
```


### Measuring model accuracy

Here, we fit two models, one simple (standard GARCH (1,1) model with Student $t$ innovations) and one complex (AR(1) GJR GARCH model with skewed Student $t$ innovations) and compare their likelihood and information criteria. Higher Likelihood can lead to the risk of over-fitting. However, lower information criteria is better.

```{r simple-GARCH}
# Simple model
tgarchspec <- ugarchspec(mean.model = list(armaOrder = c(0, 0)),
                         variance.model = list(model = "sGARCH", 
                                               variance.targeting = TRUE),
                         distribution.model = "std")
tgarchfit <- ugarchfit(data = meta_discrete_returns, spec = tgarchspec)
length(coef(tgarchfit)) # only 5 parameters
```

```{r complex-GARCH}
# Complex model
flexgarchspec <- ugarchspec(mean.model = list(armaOrder = c(1, 0)),
                            variance.model = list(model = "gjrGARCH"), 
                            distribution.model = "sstd")
flexgarchfit <- ugarchfit(data = meta_discrete_returns, spec = flexgarchspec)
length(coef(flexgarchfit)) # we now have 8 parameters
```

```{r Mean-squared-prediction-errors}
# Compute prediction errors
garcherrors <- residuals(tgarchfit)
gjrerrors <- residuals(flexgarchfit)

# Compute MSE for variance prediction of simple model
mean((sigma(tgarchfit)^2 - garcherrors^2)^2)

# Compute MSE for variance prediction of complex model
mean((sigma(flexgarchfit)^2 - gjrerrors^2)^2)
```

Mean squared prediction errors (MSE) of the complex model is slightly lower than the complex model. 

```{r likelihood-infocriteria}
# Simple model
likelihood(tgarchfit)
infocriteria(tgarchfit)

# Complex model
likelihood(flexgarchfit)
infocriteria(flexgarchfit)
```

Observations:

* Likelihood: Complex model (4654) > Simple model (4640)
* Parameter: Complex model (8) > Simple model (5)
* Akaike: Complex model (-5.344) < Simple model (-5.332)

Based on these observations, we choose complex model because of higher likelihood and lower criteria information. 

### Diagnosing absolute standardized returns

GARCH model makes strong assumption about the mean and the variance. Thus, it's essential to validate these assumptions. We can do this by analyzing the standardized returns. The fomular of standardized returns is as follows:

$$Z_{t} = \frac {R_{t} - \hat\mu_{t}}{\hat\sigma_{t}}$$

```{r absolute-standardized-returns}
# Compute the standardized returns
std_meta_ret <- residuals(flexgarchfit, standardize = TRUE)

# Check 1: Compute their sample mean and standard deviation
mean(std_meta_ret)
sd(std_meta_ret)

# CHeck 2: Correlogram of the absolute (standardized) returns
par(mfrow = c(1, 2))
acf(abs(meta_discrete_returns), 22)
acf(abs(std_meta_ret), 22)

# Check 3: Ljung-Box test
Box.test(abs(std_meta_ret), 22, type = "Ljung-Box")
```

Observations:

* Sample mean of standardized returns = -0.007348 $\approx$ 0 -> good
* Sample standard deviation of standardized returns =  1.03 $\approx$ 1 -> good
* For absolute returns: many ACF are high and significant. The variance model does a good job in capturing the volatility dynamics because the ACF of the absolute standardized returns are close to 0. -> good 
* Ljung box test: Ho: autocorrelations in the absolute standardized returns are 0. We went to have 0 to have a good model. P-value = 0.1517 > 0.05. The model is valid. -> good

### Rolling estimation

Rolling estimation is the solution to avoid look-ahead bias. Why is that?

For a given time series of returns, we can estimate the GARCH volatility using the method sigma() applied to the output from ugarchfit or by using the as.data.frame() method to the output from ugarchroll. The difference is that ugarchfit leads to an in-sample estimate of volatility obtained by estimating the GARCH model only once and using the complete time series, while ugarchroll re-estimates the model and uses only the returns that are actually observable at the time of estimation.

```{r In-sample-versus-rolling-sample-vol}
# Estimate the GARCH model using all the returns and compute the in-sample estimates of volatility
garchinsample <- ugarchfit(data = meta_discrete_returns, spec = flexgarchspec)
garchvolinsample <- sigma(garchinsample)

# Use ugarchroll for rolling estimation of the flex GARCH model 
garchroll <- ugarchroll(flexgarchspec, data = meta_discrete_returns, 
        n.start = 1000, refit.window = "moving", refit.every = 300)

# Set preds to the data frame with rolling predictions
preds <- as.data.frame(garchroll)

# Compare in-sample and rolling sample volatility in one plot
par(mfrow = c(1, 1))
garchvolroll <- xts(preds$Sigma, order.by = as.Date(rownames(preds)))
volplot <- plot(garchvolinsample, col = "darkgrey", lwd = 1.5, main = "In-sample versus rolling vol forecasts")
volplot <- addSeries(garchvolroll, col = "blue", on = 1)
plot(volplot)
```

```{r MSE-rolling-estimation}
# Compute MSE for garchroll
gjrgarchpreds <- as.data.frame(garchroll)
e  <- gjrgarchpreds$Realized - gjrgarchpreds$Mu  
d  <- e^2 - gjrgarchpreds$Sigma^2
gjrgarchMSE <- mean(d^2)
gjrgarchMSE
```

Let's plot the squared residuals and the estimated conditional variance:

```{r}
var_flex <- flexgarchfit@fit$var
resid2_flex <- flexgarchfit@fit$residuals^2
plot(resid2_flex, type = "l")
lines(var_flex, col = "green")
# How to get MAPE from this model ???
```

### Forecasting

```{r}
garchforecast <- ugarchforecast(fitORspec = flexgarchfit, n.head = 30)
```

```{r MAPE-GARCH}
# MAPE
ape <- abs(residuals(flexgarchfit)) / (sigma(flexgarchfit) - gjrerrors)
mean(ape)

mean(abs(flexgarchfit@fit$residuals) / (sigma(flexgarchfit) - gjrerrors))

f <- forecast(flexgarchfit, h = 12)
accuracy(f$mean, meta_discrete_returns)
```

### Way 2: Selecting GARCH order by AIC

As can be seen, the previous part with GARCH(1,1) model have a very high number of errors.
A 3x3 matrix is created to investigate all models from GARCH (1,1) up to and including GARCH (3,3) and tabulate their respective AIC values, observing which has the best relative fit.

```{r GARCH-order-selection}
# Create 3x3 matrix
aic_garch <- matrix(0,3,3)

# Loop to run garch order from 1 -> 3
for (i in 1:3) {
  for (j in 1:3) {
    garch_spec = ugarchspec(variance.model = list(garchOrder = c(i,j)), 
                            mean.model = list(armaOrder = c(0,0), include.mean = FALSE),
                            distribution.model = "std")
    garch_fit = ugarchfit(spec = garch_spec, data = meta_discrete_returns,
                          solver.control = list(trace = 1))
    aic_garch[i,j] <- infocriteria(garch_fit)[1]
  }
}

# Print the matrix
aic_garch

# Min value
min(aic_garch)
```

We can see that model GARCH(2,3) has the lowest information criteria. Now, we will fit the model:

```{r fit-GARCH-2-3}
garch23_spec <- ugarchspec(variance.model = list(garchOrder=c(2,3)), 
                          mean.model = list(armaOrder=c(0,0), include.mean = FALSE),
                          distribution.model = "std")

garch23_fit <- ugarchfit(spec = garch23_spec, data = meta_discrete_returns,
                        solver.control = list(trace = 1))
```



