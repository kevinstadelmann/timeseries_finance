---
title: "Meta Analysis"
author: "Quyen Duong"
date: "Last edited `r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
---

```{r setup, include = FALSE}
# Set the default mode for all the chunks
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center", 
                      fig.height = 6, fig.width = 8)
```

```{r load-packages, include=FALSE}
library(quantmod)         # download stock price
library(tidyverse)
library(dplyr)
library(ggplot2)
library(tseries)          # for ts object, ADF test
library(forecast)         # to predict price 
library(prophet)
library(astsa)            # for ARIMA model, check residual
```

# Introduction

## Motivation
The goal of the study is to compare three different machine learning methods to predict Meta stock price:

* ARIMA: Auto-regressive integrated moving average
* GARCH: Generalized auto-regressive conditional heteroskedasticity
* Prophet: a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data ^[https://facebook.github.io/prophet/]. 

## Methodology
Add text here 

```{r load-data}
# Downloading Meta ("FB") via Yahoo Finance API
Meta <- NULL
tickers_index <- c("FB")

for (Ticker in tickers_index) {
  Meta <- cbind(
    Meta,
    getSymbols.yahoo(
      Ticker,
      from = "2015-01-01",
      to = "2021-11-30",          
      periodicity = "weekly",
      auto.assign = FALSE
    )[, 6]                        # Only adjusted close price
  )
}

# Change Meta to dataframe
d_meta <- broom::tidy(Meta)

# Select relevant columns & change column names
d_meta <- d_meta %>% select(index, value) %>% 
  rename(date_meta = index, price_meta = value)

# Glimpse on the data
glimpse(d_meta)
```

# Descriptive analysis

## Stock price

Let's first have a look at the time series:

```{r plot-timeseries}
# Plot the time series
plot(Meta)
```

Meta price plot displays multiplicative trend and multiplicative seasonality. The important task at this stage is assess the time series' stationary. Obviously, according to the plot above, it is not stationary. Yet, we conduct the Augmented Dickey-Fuller (ADF), a so-called test to check whether a time series is (non-)stationary. The hypotheses are formed as follows:

* $H_{0}: \rho = 1$: Time series has a unit root, hence, non-stationary, shows a trend over time 
* $H_{1}: -1 < \rho < 1$: Time series is stationary

```{r ADF-test-price, include = TRUE}
# Conduct ADF test for price
adf.test(Meta)
```

p-value = 0.5 > $\alpha$ of 0.05: fail to reject $H_{0}$, this time series is not stationary.

```{r ADF-test-log-price}
# Conduct ADF test for logged price
adf.test(log(Meta))
```

p-value = 0.18 > $\alpha$ of 0.05: fail to reject $H_{0}$, this log-transformed time series is not stationary.

### Decompose the time series

```{r decompose-ts}
# Create timeseries object with frequency 260 days/year
ts_meta <- ts(d_meta$price_meta, start = c(2015,1), frequency = 52)

# Decompose according to TSA module
meta_decomposed <- decompose(ts_meta)
plot(meta_decomposed)

# Seasonal Decomposition of Time Series by Loess
stl_meta <- stl(ts_meta, s.window = "periodic")
plot(stl_meta)
```

## Continous returns

It's even more essential to check the histogram of Meta returns. In this case, we put the histogram and boxplot together in one graph to provide a comprehensive view over the returns:

```{r histogram-return}
# Calculating continuous returns 
returns_meta <- na.omit(diff(log(Meta)))
colnames(returns_meta)<-"returns_meta"

# Histogram
histogram_meta_return <- ggplot(returns_meta, mapping = aes(x = returns_meta)) +
  geom_histogram(color="black", fill = "grey", bins = 30) +
  #geom_density(alpha=.2, color ="blue") +
  scale_x_continuous() +
  labs(title = "Histogram and boxplot of Meta returns") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# Boxplot
boxplot_meta_return <- ggplot(returns_meta, mapping = aes(x = "", y = returns_meta)) +
  geom_boxplot(color = "black", fill = "grey") +
  scale_y_continuous() +
  coord_flip() +
   xlab("") +
  theme_minimal()

# Display two plots together
egg::ggarrange(histogram_meta_return, boxplot_meta_return, heights = 2:1)
```

The histogram of Meta returns looks left-skewed but let's check the basic statistics for skewness and kurtosis. 

```{r Skewness-Kurtosis-return}
psych::describe(returns_meta)
```

* Skew = -0.56: Moderately skewed distribution with some tails. Remarkably, there are two data points on the far left presenting the two negative returns.
* Kurtosis = 4.75: Leptokurtic distribution with long tails and concentrated toward the mean. Compared to a normal distribution, its tails are longer and fatter, and often its central peak is higher and sharper. ^[https://www.investopedia.com/terms/k/kurtosis.asp]

```{r plot-return}
# Plot the returns
plot(returns_meta)
```

As expected from Kurtosis, the plot of returns exhibits constant trend around the mean. Nevertheless, the variance of returns is not constant over time. We test ADF once more time with the returns:

```{r ADF-test-returns, include = TRUE}
# Conduct ADF test for the returns
adf.test(returns_meta)
```

p-value = 0.01 < $\alpha$: reject $H_{0}$: The continuous returns are stationary. 

# Fitting models

## ARIMA

To fit an ARIMA model, we must perform preliminary checks:

- Is the model stationary?
- Do the properties of (P)ACF match?
- Which orders of p, d, q?

### Manually choosing model

```{r acf-pacf-log-meta}
# ACF & PACF of logged meta
tsdisplay(log(Meta), points = FALSE)
```

Observations:

- ACF decays in a linear fashion and stays outside of the confidence band.
- PACF is almost at 1 at lag 1, clear cuts off at lag 1. 

```{r}
# Identifying p, q of the ARIMA(p,1,q)-model by testing different specifications
max.order <- 6 # We only allow a maximum of 8 AR- and/or MA-terms 
d <- 1         # we difference at lag 1 then the time series became stationary

# Defining the matrix in for values of the AICs for different model specifications are stored
arima_aic <- matrix(NA, ncol=max.order+1, nrow=max.order+1)
row.names(arima_aic) <- c(0:max.order) # Order of AR(p) in rows
colnames(arima_aic) <- c(0:max.order) # Order of MA(q) in columns

# Calculating and storing the AICs for different model specifications
for(i in 0:max.order){
  for(j in 0:max.order){
    arima_aic[i+1,j+1] <- Arima(y=log(Meta), order=c(i,d,j), include.constant = TRUE)$aic
  }
}
arima_aic

# Finding the model specification which minimizes the AIC
index <- which(arima_aic == min(arima_aic), arr.ind = TRUE)
ar <- as.numeric(rownames(arima_aic)[index[1]])
ma <- as.numeric(colnames(arima_aic)[index[2]])

# Estimating the optimal ARIMA-model and testing for significance of the coefficients
arima <- Arima(y=log(Meta), order=c(ar,1,ma), include.constant = TRUE)
```

Using matrix to calculate and choose the min of AIC, the result is ARIMA(5,1,5) with drift.

### Auto-Arima

```{r auto-arima}
# Fit an auto-arima
fit_auto_ari <- auto.arima(y = log(Meta), ic = c("aicc", "aic", "bic"))
fit_auto_ari

auto.arima(y = log(Meta), ic = "aic")
```

Using auto.arima, we got ARIMA(0,1,1) with drift. 

Check again why there is the differences like this from the previous part and this part.

### Residual analysis

The goal of this part is to ensure that the residuals are white Gaussian noise. After getting two ARIMA models, we evaluate the residuals of these model. 

```{r residual-check-auto-arima, results='hide',fig.keep='all'}
# Use sarima from package astsa because many plots shown
# Check residuals ARIMA(0,1,1)
sarima(log(Meta), 0,1,1)

## Check residuals ARIMA(5,1,5)
sarima(log(Meta), 5,1,5)
```

Observations:

- Standardized residuals: do not show an obvious pattern.
- Sample ACF of residuals: 95% of the ACF values should be between the confidence band. 
- Normal Q-Q plot: if the residuals are normal, the points will be in the blue line. However, there are often extreme value on the ends as in the graph. If there are no huge departures from the line, the normal assumption is reasonable. 
- Q-statistic p-values: if most points are above the blue lines, we can assume white noise. If this is not the case, there might be some correlation left in the residuals, we might consider to fit another model or add a parameter. Here, the bottom plot of ARIMA(0,1,1) displays all points avove the line. In contrast, the Lijung-Box for ARIMA(5,1,5) exhibits some points touching the line and one point under the line.
- AIC and AICc of ARIMA(5,1,5) are smaller than ARIMA(0,1,1). In contrast, BIC of ARIMA(0,1,1) is smaller than that of ARIMA(5,1,5). (i.e. -3.53 < -3.44)


### Forecasting

```{r forecast-auto.arima}
# Creating test and train dataset
d_train <- window(ts_meta, end = c(2021, 30))
d_test <- window(ts_meta, end = c(2021, 49))

# Forecasting 30 days using astsa package
sarima.for(d_train, n.ahead = 19, 1, 1, 0)
lines(d_test)

oil <- window(astsa::oil, end = 2006)
oilf <- window(astsa::oil, end = 2007)
sarima.for(oil, n.ahead = 52, 1, 1, 0)
lines(oilf)

str(oil)

# Forecasting 60 days using forecast
pred <- forecast(fit_auto_ari, level = 0.95, h = 60)
plot(pred, ylab="Meta")
```

